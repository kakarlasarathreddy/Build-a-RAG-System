{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1b13c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pypdf in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (4.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from pypdf) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b72f879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (2.28.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (1.4.39)\n",
      "Collecting langsmith<0.2.0,>=0.1.0\n",
      "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
      "     -------------------------------------- 115.2/115.2 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain_community) (8.2.3)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-win_amd64.whl (370 kB)\n",
      "     -------------------------------------- 370.7/370.7 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting langchain-core<0.2.0,>=0.1.45\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
      "     -------------------------------------- 291.3/291.3 kB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (1.23.5)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.4/50.4 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (22.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.0/53.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (1.10.12)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain_community) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain_community) (2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.45->langchain_community) (4.11.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Installing collected packages: typing-inspect, packaging, multidict, jsonpatch, frozenlist, async-timeout, yarl, marshmallow, langsmith, aiosignal, langchain-core, dataclasses-json, aiohttp, langchain_community\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 langchain-core-0.1.45 langchain_community-0.0.34 langsmith-0.1.49 marshmallow-3.21.1 multidict-6.0.5 packaging-23.2 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c0c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa32164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-text-splitters) (0.1.45)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (6.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.10.12)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (23.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (0.1.49)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2023.7.22)\n",
      "Installing collected packages: langchain-text-splitters\n",
      "Successfully installed langchain-text-splitters-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-text-splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2b744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(r\"C:\\Users\\HOME\\OneDrive\\Desktop\\2404.07143.pdf\")\n",
    "pages=loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4044e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 568, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "\n",
    "chunks=text_splitter.split_documents(pages)\n",
    "\n",
    "print(len(chunks))\n",
    "\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "877cbf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Preprint.\\n\\nUnder review.\\n\\nLeave No Context Behind:\\nEfficient Infinite Context Transformers with Infini-attention\\nTsendsuren Munkhdalai, Manaal Faruqui and Siddharth Gopal\\nGoogle\\ntsendsuren@google.com\\nAbstract\\nThis work introduces an efficient method to scale Transformer-based Large\\nLanguage Models (LLMs) to infinitely long inputs with bounded memory\\nand computation.\\n\\nA key component in our proposed approach is a new at-\\ntention technique dubbed Infini-attention.', metadata={'source': 'C:\\\\Users\\\\HOME\\\\OneDrive\\\\Desktop\\\\2404.07143.pdf', 'page': 0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f6cb613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl (28 kB)\n",
      "Collecting google-generativeai<0.6.0,>=0.5.0\n",
      "  Downloading google_generativeai-0.5.2-py3-none-any.whl (146 kB)\n",
      "     -------------------------------------- 146.8/146.8 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.27 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-google-genai) (0.1.45)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.23.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.66.2)\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "     -------------------------------------- 138.3/138.3 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.10.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.21.12)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.126.0-py2.py3-none-any.whl (12.6 MB)\n",
      "     ---------------------------------------- 12.6/12.6 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting google-ai-generativelanguage==0.6.2\n",
      "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
      "     -------------------------------------- 664.5/664.5 kB 6.0 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.8/48.8 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (6.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (0.1.49)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (8.2.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.63.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.9/96.9 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.59.2)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\home\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.26.14)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.62.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, proto-plus, httplib2, grpcio, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.59.2\n",
      "    Uninstalling grpcio-1.59.2:\n",
      "      Successfully uninstalled grpcio-1.59.2\n",
      "Successfully installed google-ai-generativelanguage-0.6.2 google-api-core-2.18.0 google-api-python-client-2.126.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.2 grpcio-1.62.2 grpcio-status-1.62.2 httplib2-0.22.0 langchain-google-genai-1.0.2 proto-plus-1.23.0 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8335e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=\"AIzaSyDeFmoBbE6wNDKftGcF0mowbgzhC5HjzUw\", \n",
    "                                               model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0d7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the chunks in vector store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Embed each chunk and load it into the vector store\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# Persist the database on drive\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "275bc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a Connection with the ChromaDB\n",
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbcbaee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db_connection to Retriever Object\n",
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "922565b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a809d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    Your task is to provide assistance based on the context given by the user. \n",
    "    Make sure your answers are relevant and helpful.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d36ed845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyDeFmoBbE6wNDKftGcF0mowbgzhC5HjzUw\", \n",
    "                                   model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "880948eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ddae99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ced721e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Gating Score Visualization Explained\\n\\nBased on the context provided, **gating score visualization** refers to the graphical representation of the gating scores (sigmoid(β)) within the compressive memory of the Infini-attention model.  This visualization, as shown in Figure 3 of the referenced paper, helps analyze the behavior of different attention heads within the model.\\n\\n**Key Points:**\\n\\n* **Gating Score:** This score, represented by sigmoid(β), determines the degree to which information is passed through the compressive memory. A score close to 0 indicates minimal information passage, while a score close to 1 signifies maximum passage. \\n* **Attention Heads:**  These are individual components within the Infini-attention model that focus on specific aspects of the input data. \\n* **Visualization (Figure 3):** The visualization likely displays the gating scores for different attention heads across various layers of the model. This allows researchers to observe patterns and identify different types of heads. \\n\\n**Types of Heads Identified:**\\n\\nThe context mentions that the visualization revealed two primary types of attention heads:\\n\\n* **Specialized Heads:** These heads have gating scores near 0 or 1, suggesting they either block or fully pass information through the compressive memory. They likely focus on specific features or patterns in the data.\\n* **Mixer Heads:**  These heads have gating scores close to 0.5, indicating they allow a moderate flow of information. They might be responsible for combining information from different sources or attending to broader contexts.\\n\\n**Importance of Gating Score Visualization:**\\n\\nUnderstanding the behavior of attention heads through gating score visualization is crucial for:\\n\\n* **Analyzing model behavior:** It provides insights into how the model processes information and which aspects of the input it prioritizes.\\n* **Improving model design:** By understanding the roles of different attention heads, researchers can refine the model architecture for better performance and efficiency. \\n* **Developing effective compressive memory techniques:**  The ultimate goal is to find a balance between simplicity and quality in compressive memory approaches for LLMs. \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"what is gating score visualization\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b26f601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Gating Score Visualization Explained\n",
       "\n",
       "Based on the context provided, **gating score visualization** refers to the graphical representation of the gating scores (sigmoid(β)) within the compressive memory of the Infini-attention model.  This visualization, as shown in Figure 3 of the referenced paper, helps analyze the behavior of different attention heads within the model.\n",
       "\n",
       "**Key Points:**\n",
       "\n",
       "* **Gating Score:** This score, represented by sigmoid(β), determines the degree to which information is passed through the compressive memory. A score close to 0 indicates minimal information passage, while a score close to 1 signifies maximum passage. \n",
       "* **Attention Heads:**  These are individual components within the Infini-attention model that focus on specific aspects of the input data. \n",
       "* **Visualization (Figure 3):** The visualization likely displays the gating scores for different attention heads across various layers of the model. This allows researchers to observe patterns and identify different types of heads. \n",
       "\n",
       "**Types of Heads Identified:**\n",
       "\n",
       "The context mentions that the visualization revealed two primary types of attention heads:\n",
       "\n",
       "* **Specialized Heads:** These heads have gating scores near 0 or 1, suggesting they either block or fully pass information through the compressive memory. They likely focus on specific features or patterns in the data.\n",
       "* **Mixer Heads:**  These heads have gating scores close to 0.5, indicating they allow a moderate flow of information. They might be responsible for combining information from different sources or attending to broader contexts.\n",
       "\n",
       "**Importance of Gating Score Visualization:**\n",
       "\n",
       "Understanding the behavior of attention heads through gating score visualization is crucial for:\n",
       "\n",
       "* **Analyzing model behavior:** It provides insights into how the model processes information and which aspects of the input it prioritizes.\n",
       "* **Improving model design:** By understanding the roles of different attention heads, researchers can refine the model architecture for better performance and efficiency. \n",
       "* **Developing effective compressive memory techniques:**  The ultimate goal is to find a balance between simplicity and quality in compressive memory approaches for LLMs. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c00bc2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Memory Retrieval and Update in the Context of Compressive Memory\\n\\nBased on the provided text, here\\'s an explanation of memory retrieval and update within the system:\\n\\n**Compressive Memory:**\\n\\nUnlike traditional memory systems that grow with the input sequence, compressive memory maintains a fixed size. It stores and recalls information efficiently with bounded storage and computational costs.\\n\\n**Memory Update:**\\n\\n*   **Adding New Information:** When new information arrives, it\\'s incorporated into the memory by modifying its parameters. The objective is to ensure this information can be retrieved accurately later.\\n*   **Mechanism:** The specific update rule and mechanism mentioned are borrowed from Katharopoulos et al. (2020) due to their simplicity and effectiveness. \\n\\n**Memory Retrieval:**\\n\\n*   **Accessing Stored Information:** The system retrieves values from the memory using attention query states when processing subsequent sequences.\\n*   **Leveraging Attention Mechanisms:** The memory retrieval process is framed as a linear attention mechanism, drawing inspiration from Shen et al. (2018). This allows the system to benefit from stable training techniques established in related methods.\\n*   **Infini-attention:** This specific approach reuses key, value, and query states from standard attention computations. Instead of discarding old KV states, they are stored in the compressive memory and retrieved later using attention query states when processing new sequences.\\n\\n**Benefits:**\\n\\n*   **Efficiency:** Compressive memory offers a more efficient approach compared to expanding memory systems, especially when dealing with long sequences of information.\\n*   **Bounded Costs:** Storage and computational costs remain manageable due to the fixed size of the memory. \\n*   **Performance:** The adopted techniques ensure competitive performance in information retrieval tasks.\\n\\n**Additional Notes:**\\n\\n*   The provided text also mentions system-level optimizations for efficient attention computation using specific hardware architectures. However, it doesn\\'t delve into the specifics of those optimizations. \\n*   The reference to \"Infini-attention\" suggests a novel approach that could be specific to the research or system described in the text. \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you please tell me about meory retival and memory update\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e11f2544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Memory Retrieval and Update in the Context of Compressive Memory\n",
       "\n",
       "Based on the provided text, here's an explanation of memory retrieval and update within the system:\n",
       "\n",
       "**Compressive Memory:**\n",
       "\n",
       "Unlike traditional memory systems that grow with the input sequence, compressive memory maintains a fixed size. It stores and recalls information efficiently with bounded storage and computational costs.\n",
       "\n",
       "**Memory Update:**\n",
       "\n",
       "*   **Adding New Information:** When new information arrives, it's incorporated into the memory by modifying its parameters. The objective is to ensure this information can be retrieved accurately later.\n",
       "*   **Mechanism:** The specific update rule and mechanism mentioned are borrowed from Katharopoulos et al. (2020) due to their simplicity and effectiveness. \n",
       "\n",
       "**Memory Retrieval:**\n",
       "\n",
       "*   **Accessing Stored Information:** The system retrieves values from the memory using attention query states when processing subsequent sequences.\n",
       "*   **Leveraging Attention Mechanisms:** The memory retrieval process is framed as a linear attention mechanism, drawing inspiration from Shen et al. (2018). This allows the system to benefit from stable training techniques established in related methods.\n",
       "*   **Infini-attention:** This specific approach reuses key, value, and query states from standard attention computations. Instead of discarding old KV states, they are stored in the compressive memory and retrieved later using attention query states when processing new sequences.\n",
       "\n",
       "**Benefits:**\n",
       "\n",
       "*   **Efficiency:** Compressive memory offers a more efficient approach compared to expanding memory systems, especially when dealing with long sequences of information.\n",
       "*   **Bounded Costs:** Storage and computational costs remain manageable due to the fixed size of the memory. \n",
       "*   **Performance:** The adopted techniques ensure competitive performance in information retrieval tasks.\n",
       "\n",
       "**Additional Notes:**\n",
       "\n",
       "*   The provided text also mentions system-level optimizations for efficient attention computation using specific hardware architectures. However, it doesn't delve into the specifics of those optimizations. \n",
       "*   The reference to \"Infini-attention\" suggests a novel approach that could be specific to the research or system described in the text. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd6bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
